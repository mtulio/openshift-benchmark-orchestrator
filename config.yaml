
config:
  workdir: ./.local

#
# OpenShift Installer Config | defaults
#
defaults:
  network:
    type: OpenShiftSDN
    cluster_cidr: 10.128.0.0/14
    cluster_prefix: 23
    machine_cidr: 10.0.0.0/16
    service_cidr: 172.30.0.0/16
  aws:
    # installer: publish
    publish: External
    # installer: .platform.aws
    platform:
      region: us-east-1
    baseDomain: ${DEFAULT_BASEDOMAIN_AWS}
    #controlPlane:
    #  type: m5.xlarge
      # TODO: check if it's supported
      #vm_spot_price: 0.192
    #compute:
    #  type: m5.xlarge
      # TODO: check if it's supported
      #vm_spot_price: 0.192

  azure:
    # installer: publish
    publish: External
    # installer: .platform.azure
    baseDomain: ${DEFAULT_BASEDOMAIN_AZURE}
    platform:
      baseDomainResourceGroupName: os4-common
      cloudName: AzurePublicCloud
      outboundType: Loadbalancer
      region: eastus

  alibabacloud:
    publish: External
    baseDomain: ${DEFAULT_BASEDOMAIN_ALIBABA}
    platform:
      region: us-east-1
      resourceGroupID: rg-aeky7tawyfdzu4i

# OpenShift Installer Config | cluster profiles
cluster_profiles:
  # AWS
  ## Get default binary from system
  aws_default:
    name: aws_default
    platform: aws

  ## GA releases (https://openshift-release.apps.ci.l2s4.p1.openshiftapps.com/)
  #> Script to download clients: hack/download-ocp-clients.sh
  aws_ga_46:
    name: aws_ga_46
    platform: aws
    installer: openshift-install-4.6.56
    oc: oc-linux-4.6.56
  aws_ga_47:
    name: aws_ga_47
    platform: aws
    installer: openshift-install-4.7.45
    oc: oc-linux-4.7.45
  aws_ga_48:
    name: aws_ga_48
    platform: aws
    installer: openshift-install-4.8.35
    oc: oc-linux-4.8.35
  aws_ga_49:
    name: aws_ga_49
    platform: aws
    installer: openshift-install-4.9.25
    oc: oc-linux-4.9.25

  ## Development builds
  aws_dev_411:
    name: aws_dev_411
    installer: openshift-install-4.10-b-release-4.11
    platform: aws
  aws_dev_master:
    name: aws_dev_master
    installer: openshift-install-master
    platform: aws
  aws_dev_latest:
    name: aws_dev_latest
    installer: openshift-install-master
    platform: aws
  aws_dev_410:
    name: aws_dev_410
    platform: aws
    installer: openshift-install-4.10.0-rc.3
    oc: oc-linux-4.10.0-rc.3

  ### CCO
  aws_dev_cco_sts:
    name: aws_dev_cco
    platform: aws
    credentialsMode: Manual
    installer: openshift-install-master
    oc: oc-linux-4.10.0-0.nightly-2022-01-10-014106
    manifest_hooks:
      - patch_cco_aws_sts
      - cluster_hook_preserve_bootstrap

  aws_dev_cco_sts_restrict:
    platform: aws
    credentialsMode: Manual
    installer: openshift-install-master
    oc: oc-linux-4.10.0-0.nightly-2022-01-10-014106
    manifest_hooks:
      - patch_cco_aws_sts
      - patch_cco_aws_sts_s3_restrict
      - cluster_hook_preserve_bootstrap

  aws_dev_cco_sts_restrict_cfront:
    platform: aws
    credentialsMode: Manual
    installer: openshift-install-master
    oc: oc-linux-4.10.0-0.nightly-2022-01-10-014106
    manifest_hooks:
      - patch_cco_aws_sts
      - patch_cco_aws_sts_s3_restrict_cloudfront
      - cluster_hook_preserve_bootstrap

  ## Other AWS profiles
  ### Profiles used on gp3 development, prior 4.10. Build references:
  ###> 2xEBS: https://github.com/mtulio/installer/pull/4/files#diff-1d1c6cd6df20b7e2fd321d88255bb4dfc9cbbe4289ee324829f5fc03ac977c9dR166-R178 
  aws_m5x1xgp2:
    name: aws_m5x1xgp2
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-1xEBS
    platform: aws
  aws_m5x2xgp2:
    name: aws_m5x2xgp2
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-2xEBS
    platform: aws
    manifest_hooks:
      - patch_machine_aws_2xDevBlocks
      - patch_machineConfig_aws_mount_etcd
  aws_m5x1xgp3:
    name: aws_m5x1xgp3
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-1xEBS
    platform: aws
    vol_type: gp3
    vol_size: 128
  aws_m5x2xgp3:
    name: aws_m5x2xgp3
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-2xEBS
    platform: aws
    vol_type: gp3
    vol_size: 128
    manifest_hooks:
      - patch_machine_aws_2xDevBlocks
      - patch_machineConfig_aws_mount_etcd
  aws_m5x1xgp3_64G:
    name: aws_m5x1xgp3
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-1xEBS
    platform: aws
    vol_type: gp3
    vol_size: 64
  aws_m5x2xgp3_64G:
    name: aws_m5x1xgp3
    installer: openshift-install-4.9-gp3m6i-monit-ebsOpt-2xEBS
    platform: aws
    vol_type: gp3
    vol_size: 64
    manifest_hooks:
      - patch_machine_aws_2xDevBlocks
      - patch_machineConfig_aws_mount_etcd

  # Azure
  azure_dev_latest:
    name: azure_default
    platform: azure
    installer: openshift-install-master
    oc: oc-linux-4.10.0-0.ci-2022-01-13-055829
    manifest_hooks:
      - cluster_hook_preserve_bootstrap

  azure_49:
    name: azure_49
    platform: azure
    installer: openshift-install-4.9.22
    oc: oc-linux-4.9.22
    manifest_hooks:
      - cluster_hook_preserve_bootstrap

  azure_410:
    name: azure_410
    platform: azure
    installer: openshift-install-4.10.0-rc.3
    oc: oc-linux-4.10.0-rc.3
    manifest_hooks:
      - cluster_hook_preserve_bootstrap

  # Alibaba
  alicloud_dev_latest:
    name: alicloud_dev_latest
    installer: openshift-install-master
    oc: oc-linux-4.10.0-0.ci-2022-01-13-055829
    platform: alibabacloud
    manifest_hooks:
      - hook_cco_alicloud_user_create
      - cluster_hook_preserve_bootstrap
    before_destroy_hooks:
      - cluster_hook_cco_alicloud_user_delete

#
# Task profiles
# > Define the profile of jobs which will be executed.
#
task_profiles:
  # FIO embeeded on etcd-perf image
  ocp_fio_etcd_defaults:
    image: quay.io/openshift-scale/etcd-perf
    base_dir: "/var/lib/etcd/"
    loop: 1

  # AWS Doc (init ebs)
  # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html
  fio_libaio_rw:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 5
    commands: |
      --rw=rw \
      --ioengine=libaio \
      --bs=16k \
      --iodepth=16 \
      --direct=1 \
      --fdatasync=1 \
      --size=3276m \

  #> AWS Docs / rec bench test
  # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/benchmark_procedures.html*
  # ToDo: how to Disable C-states in RHCOS?
  # Description: time based tests using the max IOPS as possible to read/write
  # **file** of `size` with total allocated data of `size * numjobs`
  # This setup is enough to reach 3k IOPS and keep the Queue lenght low: not so higuer than
  # (MaxIOPS/1k) = ~3. The CPU Usage will also keep 100% of all cores for m5.x
  # *the `numjobs` was changed from 16 to 5 to avoid high queue lenght.
  aws_gp_fio_psync_randwrite:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --ioengine=psync \
      --rw=randwrite \
      --direct=1 \
      --bs=16k \
      --size=1G \
      --numjobs=5 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  aws_gp_fio_psync_randread:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --ioengine=psync \
      --rw=randread \
      --direct=1 \
      --bs=16k \
      --size=1G \
      --numjobs=5 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  aws_gp_fio_psync_randrw:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --ioengine=psync \
      --rw=randrw \
      --direct=1 \
      --bs=16k \
      --size=1G \
      --numjobs=5 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  #? randread uses default ioengine (on example)
  aws_fio_randread:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 5
    commands: |
      --rw=randread \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html
  fio_ebs_initialize:
    image: ljishen/fio
    commands: |
      --filename=/dev/nvme0n1 \
      --rw=read \
      --bs=128k \
      --iodepth=32 \
      --ioengine=libaio \
      --direct=1 \
      --name=volume-initialize

  # TODO check> FIO bench comparasion st1, gp2 and gp3:
  # https://gist.github.com/niwinz/138c9ce49f484b3b66ee5f061d7f999b

  # TODO create those profiles:
  # for each: TEST={read,write,randread,randwrite,randrw}
  # params: fio --rw=TEST --direct=1 --ioengine=libaio --bs=16k --numjobs=8 --size=1G --group_reporting
  fio_libaio_read:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --rw=read \
      --ioengine=libaio \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_libaio_write:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --rw=write \
      --ioengine=libaio \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_libaio_randread:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --rw=randread \
      --ioengine=libaio \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_libaio_randwrite:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --rw=randwrite \
      --ioengine=libaio \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_libaio_randrw:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/_benchmark"
    loop: 1
    commands: |
      --rw=randrw \
      --ioengine=libaio \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  # FIO fsync
  # https://fio.readthedocs.io/en/latest/fio_doc.html#i-o-engine
  fio_sync_write:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/"
    loop: 1
    commands: |
      --rw=write \
      --ioengine=sync \
      --fdatasync=1 \
      --iodepth=1 \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  # Copy of fio_sync_write.
  # TODO add a concept of alias to don't override the
  # results running same profile more than one time in a single job
  fio_sync_write_alias:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/"
    loop: 1
    commands: |
      --rw=write \
      --ioengine=sync \
      --fdatasync=1 \
      --iodepth=1 \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_sync_read:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/"
    loop: 1
    commands: |
      --rw=read \
      --ioengine=sync \
      --fdatasync=1 \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_sync_rw:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/"
    loop: 1
    commands: |
      --rw=rw \
      --ioengine=sync \
      --fdatasync=1 \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  fio_sync_randrw:
    image: ljishen/fio
    base_dir: "/var/lib/etcd/"
    loop: 1
    commands: |
      --rw=randrw \
      --ioengine=sync \
      --fdatasync=1 \
      --bs=16k \
      --direct=1 \
      --size=1G \
      --numjobs=16 \
      --time_based \
      --runtime=180 \
      --group_reporting \
      --norandommap \

  #> Benchmark Operator
  #>> e2e-benckmarking
  #>>> etcd_perf
  ocp_e2e_bench_etcd_perf:
    git_url: git@github.com:cloud-bulldozer/e2e-benchmarking.git
    path: workloads/etcd-perf/
    run_cmd: ./run_etcd_tests_fromgit.sh

  #>>> sysbench tasks
  #>>>> CPU
  ocp_e2e_bench_sysbench_cpu_speed:
    test_name: sysbench-cpu
    test_description: |
      The cpu test is one of the most simple benchmarks in SysBench.
      In this mode each request consists in calculation of prime numbers
      up to a value specified by the --cpu-max-primes option. All
      calculations are performed using 64-bit integers. Each thread
      executes the requests concurrently until either the total number
      of requests or the total execution time exceed the limits specified
      with the common command line options.
      Speed test will check the amount of time to reach the CPU max prime.
    tests:
    # single thread
      - name: cpu
        parameters:
          cpu-max-prime: 2000
          threads: 1
      - name: cpu
        parameters:
          cpu-max-prime: 10000
          threads: 1
      - name: cpu
        parameters:
          cpu-max-prime: 20000
          threads: 1
      # multithread
      - name: cpu
        parameters:
          cpu-max-prime: 2000
          threads: 2
      - name: cpu
        parameters:
          cpu-max-prime: 10000
          threads: 2
      - name: cpu
        parameters:
          cpu-max-prime: 20000
          threads: 2

  ocp_e2e_bench_sysbench_cpu_stress:
    test_name: sysbench-cpu
    test_description: |
      The cpu test is one of the most simple benchmarks in SysBench.
      In this mode each request consists in calculation of prime numbers
      up to a value specified by the --cpu-max-primes option. All
      calculations are performed using 64-bit integers. Each thread
      executes the requests concurrently until either the total number
      of requests or the total execution time exceed the limits specified
      with the common command line options.
      Stress test will ramp up from single-thread to multi-thread in a fixed
      period until max prime. Total threads could be adjusted to fit current
      hardware. Ideally N*CPUs to reach the max stress on the system.
    tests:
    # single thread
      - name: cpu
        parameters:
          cpu-max-prime: 2000
          threads: 1
          time: 60
      - name: cpu
        parameters:
          cpu-max-prime: 10000
          threads: 1
          time: 60
      - name: cpu
        parameters:
          cpu-max-prime: 20000
          threads: 1
          time: 60
      # multithread
      - name: cpu
        parameters:
          cpu-max-prime: 2000
          threads: 2
          time: 60
      - name: cpu
        parameters:
          cpu-max-prime: 10000
          threads: 2
          time: 60
      - name: cpu
        parameters:
          cpu-max-prime: 20000
          threads: 2
          time: 60

  #>>> Mem
  ocp_e2e_bench_sysbench_mem_speed:
    test_name: sysbench-mem-speed
    test_description: |
      Memory allocation and transfer speed.
    tests:
      # Mem:Read_1KiB
      - name: memory
        parameters:
          threads: 2
          memory-oper: read
          memory-scope: global
          memory-block-size: 1KiB
          memory-total-size: 204800MiB
      # Mem:Read_1MiB
      - name: memory
        parameters:
          threads: 2
          memory-oper: read
          memory-scope: global
          memory-block-size: 1024KiB
          memory-total-size: 1024000MiB
      # Mem:Write_1KiB
      - name: memory
        parameters:
          threads: 2
          memory-oper: write
          memory-scope: global
          memory-block-size: 1KiB
          memory-total-size: 102400MiB
      # Mem:Write_1MiB
      - name: memory
        parameters:
          threads: 2
          memory-oper: write
          memory-scope: global
          memory-block-size: 1024KiB
          memory-total-size: 409600MiB


##########################################
#> Profiles
##########################################
benchmark_profiles:
  # RUN jobs on one control plane
  fio_etcd_one_cp:
    task_profiles:
      #- fio_libaio_read
      #- fio_libaio_rw
      #- ocp_fio_etcd_defaults
      - aws_fio_randrw
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: 0

  # run jobs on all control plane
  fio_etcd_all_cp:
    task_profiles:
      #- aws_ebs_initialize
      #- fio_libaio_rw
      #- ocp_fio_etcd_defaults
      - aws_fio_randrw
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: '*'
    parallel_nodes: yes

  # Run all fio tasks on all master nodes
  fio_allTasks_masterNodes:
    task_profiles:
      - fio_ebs_initialize
      - fio_psync_randwrite
      - fio_libaio_read
      - fio_libaio_write
      #- fio_libaio_rw
      - fio_libaio_randread
      - fio_libaio_randwrite
      - fio_libaio_randrw
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: '*'

  fio_fsync_masterNodes:
    task_profiles:
      #- fio_ebs_initialize #TODO fix it, it's failing
      - fio_sync_write
      - fio_sync_read
      - fio_sync_rw
      - fio_sync_write_alias
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: '*'

  fio_psync_singleMaster:
    task_profiles:
      - aws_gp_fio_psync_randread
      - aws_gp_fio_psync_randwrite
      - aws_gp_fio_psync_randrw
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: 0

  # Workload etcd-perf
  ocp_e2e_benchmarking_wk_etcd_perf:
    task_profiles:
      - ocp_e2e_bench_etcd_perf
    target_node_strategy:
      target_type: cluster

  # Workload sysbench-cpu
  # https://github.com/cloud-bulldozer/benchmark-operator/blob/master/docs/sysbench.md
  # https://github.com/mtulio/e2e-benchmarking/tree/feat-sysbench-cpu/workloads/cpu-perf
  # https://www.vpsbenchmarks.com/trials/amazon_ec2_performance_trial_22Nov2020/sysbench
  # bash -x ./oco run --cluster-name mrb410rc0 --job-name e2e_sysbench  --benchmark-profile ocp_e2e_benchmarking_workload_sysbench
  ocp_e2e_benchmarking_workload_sysbench:
    task_profiles:
      #- ocp_e2e_bench_sysbench_cpu_speed
      #- ocp_e2e_bench_sysbench_cpu_stress
      - ocp_e2e_bench_sysbench_mem_speed
    target_node_strategy:
      target_type: cluster

  # TODO new way to define tasks (dict instead of list), so now
  # it's possible to repeat one task profile in one Job execution
  fio_fsync_masterNodes2:
    run_tasks:
      #- fio_ebs_initialize #TODO fix it, it's failing
      0_fio_sync_write:
        profile: fio_sync_write
      1_fio_sync_read:
        profile: fio_sync_read
      2_fio_sync_rw:
        profile: fio_sync_rw
      3_fio_sync_write:
        profile: fio_sync_write
    target_node_strategy:
      filter_by_label: node-role.kubernetes.io/master=
      index: '*'

#
# Tool dependencies (ToDo development)
#
# dependencies:
#   - name: oc
#     path: /usr/bin/oc
#     env_name: OC_CLI

#     # Extract from CI: to run oc adm release extract --tools {image}
#   - name: openshift-install-4.9.0-0.nightly-2021-08-13-053517
#     path: ./.local/bin/penshift-install-4.9.0-0.nightly-2021-08-13
#     type: extract
#     image: registry.ci.openshift.org/ocp/release:4.9.0-0.ci-2021-08-12-161315
#     env_name: OC_INST

#   # Build installer from src
#   # TODO add instructions to build
#   # Ref PR: https://github.com/mtulio/installer/pull/4
#   # $(which time) -v ./hack/build.sh
#   - name: openshift-installer-4.9-gp3m6i-monit-ebsOpt-1xEBS
#     path: ./.local/bin/openshift-installer-4.9-gp3m6i-monit-ebsOpt-1xEBS
#     type: git
#     repo: git@github.com:mtulio/installer.git
#     version: SPLAT-254s1
#     env_name: OC_INST
#   - name: openshift-installer-4.9-gp3m6i-monit-ebsOpt-2xEBS
#     path: ./.local/bin/openshift-installer-4.9-gp3m6i-monit-ebsOpt-2xEBS
#     env_name: OC_INST
#     type: git
#     repo: git@github.com:mtulio/installer.git
#     version: SPLAT-254s1v2
